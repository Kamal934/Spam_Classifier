{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot  as plt\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import  SnowballStemmer\n",
    "from nltk.corpus import  stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import  accuracy_score,confusion_matrix,precision_score\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "File = r'sms_spam.csv'\n",
    "df= pd.read_csv(File,encoding='latin-1')\n",
    "df.columns\n",
    "\n",
    "\n",
    "df.rename(columns={'v1':'target','v2':'text_data'},inplace=True)\n",
    " \n",
    "#spam is 1 and ham is 0\n",
    "encoder= LabelEncoder()\n",
    "df['target']=encoder.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_gen_func(text, stop= set(stopwords.words('english'))\n",
    "    ,stemmer= SnowballStemmer('english')):\n",
    "   \n",
    "    ## convert the message into lower case\n",
    "    message= wordpunct_tokenize(text.lower())\n",
    "    # empty list\n",
    "    filter=[]\n",
    "    for list_1 in message:\n",
    "        if list_1 not in stop and (list_1.isalpha() or list_1.isalnum()) :\n",
    "\n",
    "            stems= stemmer.stem(list_1)\n",
    "            filter.append(stems)\n",
    "            \n",
    "    return ' '.join(filter)\n",
    "df['transfer']= df['text_data'].apply(Make_gen_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9748878923766816\n",
      "[[941   0]\n",
      " [ 28 146]]\n",
      "Recall: 0.8390804597701149\n",
      "Precision:1.0\n",
      "f1_score: 0.9125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf=TfidfVectorizer(max_features=3000)\n",
    "x=tf.fit_transform(df['transfer']).toarray()\n",
    "y=df['target'].values\n",
    "\n",
    "## train the data\n",
    "X_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=4)\n",
    "## classifier on of the  best trainset accourding precision \n",
    "\n",
    "r_boost= RandomForestClassifier()\n",
    "r_boost.fit(X_train,y_train)\n",
    "y_pred3= r_boost.predict(x_test)\n",
    "print(f'accuracy: {accuracy_score(y_test,y_pred3)}')\n",
    "print(confusion_matrix(y_test,y_pred3))\n",
    "print(f'Recall: {metrics.recall_score(y_test,y_pred3)}')\n",
    "print(f\"Precision:{precision_score(y_test,y_pred3)}\")\n",
    "print(f\"f1_score: {metrics.f1_score(y_test,y_pred3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tf,open(\"vectorizer.pkl\",'wb'))\n",
    "pickle.dump(r_boost,open(\"model.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# email=['Congratulations! You have been randomly selected as the winner of 1 crore rupees in our latest sweepstakes!To claim your prize, please click on the link below and enter your personal information. Once you have submitted your information, we will be in touch with you to arrange for the prize money to be deposited into your account.']\n",
    "# email_2= ['Happy Fathers Day! I hope you have a wonderful day.I wanted to take this opportunity to tell you how much I love and appreciate you. You are the best father anyone could ask for. You have always been there for me, no matter what. You have taught me so much about life, and I am so grateful for your guidance and I remember when I was little, you would take me fishing and camping. We would have so much fun together. You taught me how to bait a hook, how to build a campfire, and how to find my way back to the campsite in the dark.As I got older, you were always there to help me with my homework. You would sit with me for hours, helping me to understand the concepts that I was struggling with. You never gave up on me, even when I wanted to give up on myself.You have always been my biggest fan. You have cheered me on at my sporting events, you have been there to celebrate my successes, and you have been there to comfort me during my failures. You have always believed in me, even when I didnt believe in myself.I am so lucky to have you as my father. You are the most amazing man I know. I love you very much.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_term_matrix = tf.transform(email_2)\n",
    "# predict=r_boost.predict(doc_term_matrix)\n",
    "\n",
    "# if predict==1:\n",
    "#     print(\"Spam\")\n",
    "# else:\n",
    "#     print(\"ham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
